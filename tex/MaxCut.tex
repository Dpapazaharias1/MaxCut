\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{dsfont}
\usepackage[ruled,vlined]{algorithm2e}
\usetikzlibrary{intersections, patterns, decorations, automata,positioning,trees,calc}
\pgfplotsset{compat=newest}

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\title{Relaxations of the Maximum Cut Problem}
\author{Demetrios V. Papazaharias, Carter Mann, Luca Wrabetz\\ \small Department of Industrial and Systems Engineering \\
\small University at Buffalo, Bell Hall, Buffalo, New York, 14260\\\small $\lbrace \text{dvpapaza, cjmann3, lucawrab}\rbrace$@buffalo.edu}
\date{December 2019}

\theoremstyle{plain}
\newtheorem{prop}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{claim}{Claim}
\theoremstyle{definition}
\newtheorem{defn}{Definition}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\begin{document}
\maketitle
\begin{abstract}
    Maximum cut is a classic NP-Hard problem in combinatorial optimization. In this work we present several relaxations for the maximum cut problem. 
\end{abstract}

\clearpage
\section{Introduction}\label{sec:Introduction}
\section{Mathematical Formulations}\label{sec:Formulations}
\section{Relaxations for Max Cut}\label{sec:Relaxations}
\subsection{Eigenvalue Relaxation}\label{subsec:Eigenvalue}

\begin{prop}
The optimal value of $z^*$ in the maxcut problem defined on graph $G=(V,E)$ satisifes
\[
    z^* \leq z^{ev} := \dfrac{n}{4} \lambda_{max}(L(G))
\]
\end{prop}

\begin{proof}
    Consider the maximization problem 
    \[
    \max\lbrace \mathbf{z}^\top L(G) \mathbf{z}\,|\,\mathbf{z} \in \lbrace -1,1 \rbrace^n  \rbrace
    \]
    Since $L(G) = D(G) - A(G)$, then $L(G)_{ii} = \sum_{j\in V} w_{ij}$ for $i \in V$ and $L(G)_{ij} = -w_{ij}$ for $i,j \in V$ such that $i \neq j$. We expand the objective function and obtain
    \[
        \max_{\mathbf{z} \in \lbrace -1,1 \rbrace} \sum_{i \in V}\sum_{j \in V} w_{ij} z_i z_i - \sum_{i \in V}\sum_{j \in V} w_{ij}z_i z_j
    \]
    Furthermore,
    \[
        \max_{\mathbf{z} \in \lbrace -1,1 \rbrace} \sum_{i \in V} \sum_{j \in V} w_{ij} (z_i z_i - z_i z_j) 
    \]
    Since $z_i \in \lbrace -1, 1 \rbrace$ then $z_i z_i=1$, we can simplify the objective function to
    \[
        \max_{\mathbf{z} \in \lbrace -1,1 \rbrace} \sum_{i \in V} \sum_{j \in V} w_{ij} (1- z_i z_j)
    \]
    From the previous section we saw an almost identical formulation for max cut. The only difference being a multiplier of $\frac{1}{4}$. Let $z^*$ represent the optimial solution for max cut
    \begin{equation}\label{eq:optimalZLaplace}
        z^* = \frac{1}{4} \max \lbrace \mathbf{z}^\top L(G) \mathbf{z} \,|\, \mathbf{z} \in \lbrace -1,1 \rbrace^n \rbrace
    \end{equation}
    Taking the continuous relaxation of (\ref{eq:optimalZLaplace}), namely $z_i \in \left[-1,1 \right]$ for $i \in V$, is equivalent to maximizing
    over the norm infinity, $\norm{\mathbf{z}}_\infty \leq 1$. We can relax this further by maximizing over a ball of radius $\sqrt{n}$. In other words,
    our region is now defined where $\norm{\mathbf{z}} \leq \sqrt{n}$. 
    \begin{equation}
    z^* \leq \frac{1}{4} \max \lbrace \mathbf{z}^\top L(G) \mathbf{z} \,|\, \mathbf{z} \leq \sqrt{n} \rbrace
    \end{equation}    
    We can define our problem over the unit ball with a simple transformation. Let $\norm{\mathbf{z}} = \sqrt{n} \mathbf{x}$ and
    we now have
    \begin{equation}
        z^* \leq \frac{n}{4} \max \lbrace \mathbf{x}^\top L(G) \mathbf{x} \,|\, \norm{\mathbf{x}} \leq 1 \rbrace
    \end{equation}  
    Since for any symmetric matrix $\mathbf{A}$, $\max\lbrace \mathbf{x}^\top \mathbf{A} \mathbf{x}\,|\, \norm{\mathbf{x}} \leq 1 \rbrace = \lambda_{\max(\mathbf{A})}$ 
    and $L(G)$ is symmetric, then we have 
    \begin{equation}
    z^* \leq z^{ev} := \dfrac{n}{4} \lambda_{max}(L(G))
    \end{equation}
\end{proof}



\begin{prop}
    The optimal value of $z^*$ in the maxcut problem defined on graph $G=(V,E)$ satisifes
    \[
        z^* \leq z^{ev} := - \frac{1}{4}\sum_{i=1}^n u_i + \dfrac{n}{4} \lambda_{max}(L(G) + diag(\mathbf{u}))
    \]
    for all $\mathbf{u} \in \mathbb{R}^n$
\end{prop}

\begin{proof}
    Consider the maximization problem
    \begin{equation}\label{eq:propopt2}
        \max\lbrace \mathbf{z}^\top (L(G) + diag(\mathbf{u})) \mathbf{z} | \mathbf{z} \in \lbrace -1,1\rbrace \rbrace
    \end{equation}
   
    From the previous proof, we perform a similar technique to (\ref{eq:propopt2}) to obtain the following optimization problem 
    \[
    \max_{\mathbf{z} \in \lbrace -1,1 \rbrace} \sum_{i \in V}\left(\sum_{j \in V} w_{ij} + u_i \right) z_i z_i - \sum_{i \in V}\sum_{j \in V} w_{ij}z_i z_j
    \] 
    Rearranging terms and using the fact that $z_i z_i = 1$,
    \begin{equation}
        \max_{\mathbf{z} \in \lbrace -1, 1\rbrace} \sum_{i = 1}^n \sum_{j=1}^n w_{ij} (1 - z_i z_j) + \sum_{i = 1} u_i \label{eq:eig2}
    \end{equation}
    Which is closely related to the objective function in our prevoius formulation. We obtain the following relationship between (\ref{eq:eig2}) and $z^*$:
    \[
      z^* = \frac{1}{4} \max\lbrace \mathbf{z}^\top (L(G) + diag(\mathbf{u})) \mathbf{z} \,|\, \mathbf{z} \in \lbrace -1,1\rbrace \rbrace - \frac{1}{4}\sum_{i=1}^n u_i   
    \]
    We repeat the process from the previous proof of relaxing the variables so that they are continuous and then further relaxing this problem onto a ball of radius $\sqrt{n}$.
    \[
        z^* \leq \frac{1}{4} \max\lbrace \mathbf{z}^\top (L(G) + diag(\mathbf{u})) \mathbf{z} \,|\, \norm{\mathbf{z}} \leq \sqrt{n} \rbrace - \frac{1}{4}\sum_{i=1}^n u_i
    \]
    Let $\mathbf{z} = \sqrt{n} \mathbf{x}$. 
    \[
        z^* \leq \frac{n}{4} \max\lbrace \mathbf{x}^\top (L(G) + diag(\mathbf{u})) \mathbf{x} \,|\, \norm{\mathbf{x}} \leq 1\rbrace - \frac{1}{4}\sum_{i=1}^n u_i
    \]
    Finally, we obtain the inequality
    \begin{equation}
        z^* \leq z^{ev}(\mathbf{u}) = -\frac{1}{4}\sum_{i=1}^n u_i + \dfrac{n}{4} \lambda_{max}(L(G) + diag(\mathbf{u}))
    \end{equation}
\end{proof}
    
\subsection{Lagrangian Dual}\label{subsec:LDbound}

In the previous section we have proved several upper bounds on max cut based on the Laplace $L(G)$, including one which changes of the diagonal of $L(G)$ with some vector $\mathbf{u} \in \mathbb{R}^n$. In this section we will
compute the Lagrangian dual bound of maximum cut, which corresponds to the values of $\mathbf{u}$ such that $z^{ev}(\mathbf{u})$ is minimized.
\[
    z^{LD} = \min\Bigg\lbrace -\frac{1}{4}\sum_{i=1}^n u_i + \dfrac{n}{4} \lambda_{max}(L(G) + diag(\mathbf{u})) \,\Bigg|\, \mathbf{u} \in \mathbb{R}^n \Bigg\rbrace
\]
Consider the gradient of our objective function, $\nabla z^{ev}(\mathbf{u})$. In order to compute $\nabla \lambda_{max}(L(G) + diag(\mathbf{u}))$ we first use the fact that $L(G) + diag(\mathbf{u})$ is a symmetric square matrix and therefore $\lambda_{max}(L(G) + diag(\mathbf{u})) = \max\lbrace \mathbf{x}^\top (L(G) + diag(\mathbf{u})) \mathbf{x} \,|\,\norm{\mathbf{x}} \leq 1\rbrace$. This optimization problem can further be expanaded to
\[
\max_{\norm{\mathbf{x}} \leq 1} \sum_{i \in V} \left(\sum_{j \in V} w_{ij} + u_i \right) x_i x_i - \sum_{i \in V} \sum_{j\in V} w_{ij}x_i x_j 
\]
We can see that this objective value is maximized for $x_k = 1$ where $k = \argmax_i\large\lbrace \sum_{j \in V} w_{ij} + u_i \, |\, \sum_{j \in V} w_{ij} + u_i  > 0\large\rbrace$, and $x_i = 0$ for $i \in V \setminus \lbrace k \rbrace$. If there exists no positive value of  $\sum_{j \in V} w_{ij} + u_i $ then the objective function is maximized for $\mathbf{x} = \mathbf{0}$. Therefore, $\nabla \lambda_{max}(L(G) + diag(\mathbf{u})) = e_k$ if $ \lambda_{max}(L(G) + diag(\mathbf{u}))  \geq 0$ and $\mathbf{0}$ otherwise and  $\nabla z^{ev}(\mathbf{u})$ can be computed as
\[
 \nabla z^{ev}(\mathbf{u})_k = \begin{cases}
 \frac{n-1}{4} \quad& \text{if }k =\argmax_i\Big\lbrace \sum_{j \in V} w_{ij} + u_i  \,\Big|\, \sum_{j \in V} w_{ij} + u_i  > 0\Big\rbrace\\
 -\frac{1}{4} \quad&\text{otherwise}
 \end{cases}
\]
\subsubsection{Subgradient Algorithm}\label{subsubsec:Subgradient}

We implement the following subgradient algorithm in order to compute $z^{LD}$. We postpone details on our implementation decisions such as stopping criteria, initial solutions and choice of sequence $h_k$ for a later section.

\vspace{0.2cm}

\begin{algorithm}[H]
	\SetAlgoLined
	\KwResult{Computes the Lagrangian dual bound $z^{LD}$}
	Select an initial solution $\mathbf{u}_0$ and appropriate sequence $\lbrace h_k \rbrace_{k=0}^\infty$\;
	\For{$k \geq 0$}{
		Compute $z^{ev}(\mathbf{u})$ and $\nabla z^{ev}(\mathbf{u})$\;
		$\mathbf{u}_{k+1} \gets \mathbf{u}_k - h_k \frac{\nabla z^{ev}(\mathbf{u})}{ \norm{\nabla z^{ev}(\mathbf{u})}}$\;
	}
	\caption{Subgradient Algorithm for MaxCut}
\end{algorithm}

\end{document}